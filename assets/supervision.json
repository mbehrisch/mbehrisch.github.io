[{
  "title" : "Bachelor of Science",
  "thesis" : "User-Guided Matrix Sorting based on 2D Projections (Benutzergesteuerte Matrix Sortierung basierend auf 2D Projektionen)",
  "student" : "Michael Hundt",
  "start" : "2013",
  "end" : "2013",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Bachelor of Science",
  "thesis" : "Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Self-Organizing Maps",
  "student" : "Frederik Dennig",
  "start" : "2016",
  "end" : "2016",
  "titleshort": "B.Sc.",
  "abstract" : "The retrieval of useful data from large multidimensional datasets is one of the most challenging problems. The most important aspect of this problem is that usually only a small portion of the data of a dataset is relevant in respect to a given analysis-goal. Due to this, there is a need for efficient tools, which are able to extract meaningful information from a dataset. In this thesis, we present a new instantiation of the Feedback– Driven Interactive View Exploration (short FDIVE) Pipeline. Our new approach on the exploration of multidimensional datasets is based on interactive Self–Organizing Maps. We mainly use Self–Organizing Maps to partition the dataset into smaller groups of similar data elements. This facilitates the efficient annotation of data as relevant or irrelevant. In this context we introduce the new concept of 'nested Self–Organizing Maps'. The resulting annotation is the basis of the subsequent data reduction step. Self–Organizing Maps also provide a means of visualizing the dataset, thus supporting the analyst in his decision–making. In the scope of our work, we extended the FDIVE Pipeline with two new modules. Firstly, we added the adaptive feature vector selection, which allows the selection of the most descriptive feature vector, based on the annotation, if more than one feature vector is available for the analyzed dataset. Secondly, we added an 'Interaction History', to enable the analyst to return to a previous state of the analysis-process. Furthermore, the 'Interaction History' assists the analyst by visualizing the course and progress of the analysis. We show the usefulness of our work by the examination of usecases and a through evaluation of the 'Interaction History'. We conclude with a discussion of weaknesses and possible improvements.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Subspace Nearest Neighbor Search in High-Dimensional Data: Detecting Relevant Subspaces for Similar Object Retrieval",
  "student" : "Michael Hund",
  "start" : "2015",
  "end" : "2015",
  "abstract" : "Searching for subspaces in a high-dimensional space is crucial for many different applications. Patterns in the data, detected by clustering, classification or nearest neighbor search, occur often only in a low subset of dimensions (=subspace) of the original high-dimensional space. The detection of these interesting and meaningful subspaces is difficult due to the exponential number of possible combinations of dimensions and the so-called curse of dimensionality which obstructs the application of common data analysis techniques in high-dimensional data. While subspace search has already been applied to clustering and outlier detection, the field of subspace nearest neighbor search has not been addressed by the research community so far. The first part of this master thesis gives a comprehensive introduction into this new research branch by discussing the challenges that arise when searching for different nearest neighbors in different subspaces and the consequential requirements for for subspace nearest neighbor search. Moreover, ideas and aspects for an appropriate subspace model are developed. Additionally, the relation to subspace clustering and subspace outlier detection is described in a comprehensive related work chapter. The main contribution of this thesis is the second part which describes a novel algorithm called SuNCo which detects subspaces based on co-occurring nearest neighbors in different dimensions. Given a user-defined query object q, the algorithm extracts globally characteristic dimensions based on the value of q and determines the set of nearest neighbors in every dimension separately. Afterwards, dimensions are combined to subspaces by intersecting the nearest neighbors of the respective dimensions. Analyzing co-occurring data items in different dimensions differs much from existing approaches that typically analyze the data distribution in a given subspace. With the help of SuNCo, different nearest neighbors in different heterogeneous subspaces can be detected. The last part of this thesis is evaluating of SuNCo by exploring different subspaces and nearest neighbors in a world dataset. Furthermore, the algorithm is tested for scalability and accuracy measures on a synthetic benchmark dataset.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Sketch-based retrieval for Bivariate Data using Image-based Descriptors",
  "student" : "Lin Shao",
  "start" : "2013",
  "end" : "2013",
  "abstract" : "",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
} ,{
  "title" : "Master of Science",
  "thesis" : "Improved similarity computation methods for heterogenous text corpora, exemplified by the comment to news paragraph assignment problem",
  "student" : "Jürgen Schniertshauer",
  "start" : "2012",
  "end" : "2012",
  "abstract" : "In Information Retrieval (IR), the computation of similarity between text documents has been studied intensively and many approaches exist to date. Techniques include bag-of-words approaches based on term/document frequency vectors or sets of synonyms, techniques from Natural Language Processing such as named entity extraction, sentiment analysis, or feature-based methods. IR applications often consider the matching of full length documents from more or less homogeneous text repositories to each other. Recently however, the Social Web gives rise to novel IR applications in which texts that show to be heterogeneous with respect to size and style of writing, need to be compared. We study the problem of matching short, textually heterogeneous user comments to corresponding sections of full length, professionally edited, news articles. The goal is to identify appropriate similarity functions, which are required for effective layout generation, analysis, or other tasks. We create a ground truth data set from real web news and user data on which we are experimentally compare the effectiveness of matching user comments to news paragraphs based on appropriately defined text similarity functions.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Design and Evaluation of a Focus+Context-based Visualization for Relational Text. (Design und Evaluierung einer fokus- und kontextbasierten Visualisierung für relationale Texte)",
  "student" : "Matthias Ziecker",
  "start" : "2012",
  "end" : "2012",
  "abstract" : "(In German) Diese Masterarbeit befasst sich mit der Analyse, dem Design und der Evaluierung einer Anwendung zur Darstellung relationaler Texte. Mit Hilfe der Anwendung lassen sich beispielsweise Online-Nachrichtenartikel samt zugehörigen Leser-Kommentaren darstellen. Dafür wurde das Themengebiet anhand von wissenschaftlichen Arbeiten rund um die Darstellung von Texten erschlossen und bewertet. Auf Basis dessen wurde eine Anwendung designt und anschlie-ßend implementiert. Die Anwendung ist in der Programmiersprach Java und der Programmier-schnittstelle (API) für grafische Oberflächen „AWT/SWT“ geschrieben. Im Anschluss der Entwicklung wurde ein Experiment mit 24 zufälligen Probanden durchgeführt, um sowohl die Stärken als auch weiteres Potenzial der Anwendung herauszufinden. Die Anwendung dient primär dazu, dem Leser die Benutzerkommentare passend zum gelesenen Absatz, in einer nach Relevanz geordneten Reihen-folge, darzustellen.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Visual Analytics of Parallel-Performance Data: Automatic Identification of Relevant and Similar Data Subsets",
  "student" : "Laura von Rueden",
  "start" : "2015",
  "end" : "2015",
  "abstract" : "Performance-analysis tools are indispensable for understanding and optimizing the behavior of parallel programs running on increasingly powerful supercomputers. However, with hardware and software complexity on the rise, performance data and even performance profiles are becoming so data intensive that their analysis poses serious challenges. The solution proposed by this thesis is to simplify the analysis of parallel-performance data through a search-space reduction using visual analytics. This thesis presents a concept for the search-space reduction of profile-based performance data consisting of an automatic identification of (1) relevant, and (2) similar data subsets and investigates suitable methods for both steps. It exemplifies that the potential relevance of performance-data subsets can be estimated with visual-quality analysis applied to their virtual-topology views. It demonstrates further that these views can be classified according to visual features and that the views assigned to each feature class can be partitioned into similarity groups, each representing a particular performance phenomenon. Through the automatic identification of relevant and similar data subsets, this thesis classifies the Sweep3D performance data set in five similarity groups and thus achieves a search-space reduction of 80%. The results of this thesis show that performance profiles can be even more condensed to similarity groups, each representing a particular performance phenomenon. Such a condensation can reduce the time needed for performance analysis significantly.",
  "titleshort": "M.Sc. Co-Supervision with Marc-Andre Hermans, German Research School for Simulation Science, Aachen",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier",
  "student" : "Fatih Korkmaz",
  "start" : "2014",
  "end" : "2014",
  "abstract" : "The extraction of relevant and meaningful information from multi-dimensional data is a challenging problem. One of the reasons is that the number of possible representations grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Partially, Focus+Context or Semantic Zoom Interfaces can help to efficiently search for interesting views or data segments by using abstract overview visualizations. Yet these exhibit scalability problems for very large data sets regarding visualization techniques. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. In this work we introduce a framework for a feedback-driven interactive view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user’s preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets and one synthetic dataset. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Interactive Exploration of Subspaces in Hierarchical Categorical Data",
  "student" : "Tayyebeh Zad Abedini Masouleh",
  "start" : "2016",
  "end" : "2016",
  "abstract" : "The amount of available categorical data constantly increased over the last decades. With new sources especially in the web environment, e.g. social networks, movie data bases or customer behavior data, appropriate analysis techniques are needed. While not only the size of such data sets tremendously increased in recent years, also the dimensionality reached a point where standard statistical techniques like the analysis of contingency tables quickly reach the limit of feasibility. Furthermore, the goals of analysis are extremely user dependent and therefore vary a lot. In order to overcome these challenges, an analysis system is needed that is able to examine various perspectives of a data set and at the same time able to deal with meta data that can considerably facilitate the knowledge gaining process. Often categorical data can be enhanced by representing the dimensions in a semantic hierarchy. The hierarchical structuring of variables helps to interpret the data as well as the analysis outcome more effectively but also to reveal relationships and patterns in it. Additionally, higher dimensional data constitutes a problem for most analysis techniques since not all of the dimensions need to contain valuable information. As a consequence of these illustrated challenges, the goal of this work is to design a web-based visual analytics tool that provides a set of interactive visualizations coupled with proper analysis methods to find interesting subspaces in the data. Since we do not want to analyze the full range of dimensions at once but rather concentrate on interesting subsets, we follow the idea of a bottom-up approach in which the user himself selects the analyzed dimensions in a semi-automatic way. We created an intuitive and easily accessible analysis platform that excels in a modular set-up. This thesis evolved from a preliminary work, in which an extensive study was conducted to summarize the existing literature of interactions applied on matrix visualizations. Thereby, 105 papers of the years 2003 to 2015 were tagged with a number of keywords. After the creation of this taxonomy data set, the keywords were hierarchically structured. The result was a hierarchical, categorical data set whose first analysis with common methods was not satisfactory for us. Consequently, a second goal of this thesis is to apply the herein presented web-based analysis tool to this taxonomy data set in order to find relationships and similarities between the categories as well as discover missing parts and gaps in the current research of matrix visualizations.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Interactive Evaluation of Feature Vectors for Matrix Patterns",
  "student" : "Nayeem Khan",
  "start" : "2016",
  "end" : "2016",
  "abstract" : "",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Bachelor of Science",
  "thesis" : "Evaluating Graphical Perception of Treemaps using Capsule Networks",
  "student" : "Willem Hulst",
  "start" : "2020",
  "end" : "2020",
  "abstract" : "Due to the prevalence of neural networks in the state-of-the-art in image recognition, it is interesting to examine the perception performance of these networks on graphical data formats. In this project, we pick treemaps as the specific form of data visualisation. A treemap is a form of hierarchical data visualisation, based on square tile mappings. In this project, we will evaluate the perception capabilities of a specific type of neural network: a capsule network (CapsNet). This network is based on layers of vectors (neurons) that read images. Using a unique 'routing by agreement' algorithm, the image data is routed through the network. Images are then classified   based on the interpreted data. The network is trained on a large set of treemaps, and tested using   smaller sets of treemaps with varying features. An evaluation of the graphical perception performance of the CapsNet is conducted, alongside several sub-experiments to examine how resilient   the network is to changes in the image data. We conclude that the trained network performs   classification at an accuracy above the random guess threshold, but it is unsuited for the purpose  of classifying treemaps. Future research is warranted, as novel CapsNet architectures and better   training could improve performance.",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Interactive visual pattern search in large-scale multivariate sequential data using locality sensitive hashing algorithms",
  "student" : "Dylan Kruyff",
  "start" : "2020",
  "end" : "2021",
  "abstract" : "As modern technology keeps advancing, more and more data is generated every second. Multiple sensors and devices produce continuous data streams (multivariate time series) which can contain a lot of interesting information (patterns).  But finding these patterns is far from trivial, as the data is too large for a human to understand and find patterns, yet the ‘interestingness’ of a pattern is hard to capture by unsupervised machine learning alone because of the complexity of patterns in this type of data. In my upcoming presentation I will discuss how we can solve the problem of finding interesting patterns in multivariate time series by combining the strengths of human expertise and machine learning. Using relevance feedback and locality sensitive hashing, we can achieve this goal in real-time and make the process intuitive by using visual analytics.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Bachelor of Science",
  "thesis" : "Evaluating Graphical Perception of Treemaps using Capsule Networks",
  "student" : "Willem Hulst",
  "start" : "2020",
  "end" : "2020",
  "abstract" : "Due to the prevalence of neural networks in the state-of-the-art in image recognition, it is interesting to examine the perception performance of these networks on graphical data formats. In this project, we pick treemaps as the specific form of data visualisation. A treemap is a form of hierarchical data visualisation, based on square tile mappings. In this project, we will evaluate the perception capabilities of a specific type of neural network: a capsule network (CapsNet). This network is based on layers of vectors (neurons) that read images. Using a unique 'routing by agreement' algorithm, the image data is routed through the network. Images are then classified   based on the interpreted data. The network is trained on a large set of treemaps, and tested using   smaller sets of treemaps with varying features. An evaluation of the graphical perception performance of the CapsNet is conducted, alongside several sub-experiments to examine how resilient   the network is to changes in the image data. We conclude that the trained network performs   classification at an accuracy above the random guess threshold, but it is unsuited for the purpose  of classifying treemaps. Future research is warranted, as novel CapsNet architectures and better   training could improve performance.",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Bachelor of Science",
  "thesis" : "Multivariate NodeTrix Visualization",
  "student" : "Casper Stiekema",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "As big data sets become easier to collect, hardware becomes more capable and algorithms become faster and more efficient, it is important that the tools people use to keep data readable evolves as well. This is done by developing data visualization models and distributing existing theoretical models as usable tools on platforms. One of these developed models is NodeTrix, a network representation model. It uses a combination of node-link diagrams, for the global overview, and matrices, for dense clusters, to show networks. The interactive data representation tool, allows analysts to create a clear visualization of communities. In this project, we attempt to move NodeTrix into the browser environment, so that it can be more easily accessed. The expected result is, the web-browser draft-version of NodeTrix that additionally allows for directed network visualization.",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
} 
,{
  "title" : "Bachelor of Science",
  "thesis" : "Semantic Substrates Implementation with current Web-technologies",
  "student" : "Boris de Graaf",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "In order to explore the, potentially high-dimensional, data aspects within graph/relational/ network data Semantic Substrates has been proposed by Shneiderman et al. tes}. This important visualization's implementation is outdated and not web-capable rendering it insufficient for current research efforts. The goal of this project is to develop and implement a scalable and modifiable, web-based implementation and software architecture for Semantic Substrates. This architecture will be based on React components and will externalize data handling into state-of-the-art data handling frameworks, like Redux.",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Bachelor of Science",
  "thesis" : "Deep learning multidimensional projections using feed-forward networks with steerable input",
  "student" : "Joep Robben",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "Research of Espadoto, Hirata and Telea found that classic dimensionality reduction (DR) methods suffer from disadvantages. They, therefore, used deep neural networks to perform the task of dimensionality reduction more efficiently. The neural networks are trained with training data and precomputed projections, which were generated by classic DR methods, such as t-SNE. Then the neural network, which now serves as a universal function approximator, can be used to generate new, accurate projections by providing it with test data. The research claimed that this technique can be applied to any DR method, and that it will be more efficient than the standard method. This claim will be the foundation of this thesis. We will build upon the research of Espadoto et al. by introducing (variational) auto-encoder networks of PCA, UMAP, MDS and t-SNE projections. To further expand their methods, we will introduce the possibility of training one network on multiple DR methods simultaneously. Therefore, in the inference phase, a user can choose the exact proportions of different DR methods they want the neural network to replicate. To measure the performance of the neural networks, a standard evaluation procedure will be determined by creating a loss/ cost function  ",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
}
,{
  "title" : "Bachelor of Science",
  "thesis" : "Metric Research in the Lean Analytics: A Case Study of GraphPolaris",
  "student" : "Roan Bijleveld",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "Over the last few decades, a lot of research has been done on different user-interface research methodologies. However, academic experiments on these methods have rarely been performed with automated large-scale tools that can retrieve information showing which updates/implementations have an effect. Modern day webtools have the ability to automatically accumulate large amounts of user data and run automated experiments. This research focusses on the validation of these tools to help data-driven startups. GraphPolaris is a startup that focusses on the interactive visual exploration of graph data through visual analytics. The company is a lean startup that shortens the development cycle and focusses on validating iterative releases based on customer feedback. This type of setup can be a potential testbed for my research. My goal for this project is to do research on the business intelligence part of the company called 'Lean Analytics'. Examples of this are finding ways to retrieve general usage statistics and researching and setting up A/B testing facilities. The objective here is to find both qualitative and quantitative metrics that show the team which updates/implementations have an effect on the product. In addition to this, we create a framework to place these metrics on a scale from positive to negative effects. These metrics can guide the team on which parts of the product to iterate. My goal for this project is to find at least one set of actionable metrics that can be implemented for the daily operations of the GraphPolaris team and for the improvement of the company. The project would be successful if the metrics given provided the company with a positive influence on daily operations.",
  "titleshort": "B.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Measuring the quantity of differential privacy for users records data: A visualization approach",
  "student" : "Bruno Dubota",
  "start" : "2020",
  "end" : "2021",
  "abstract" : "Nowadays, more than ever data comes from different sources, providing an  opportunity to various threads. Various privacy issues such as linkage, data breaches, false identities and other frauds concern both people and organizations.  In order to deal with such a problem, the term Privacy-preserving  approaches with Differential Privacy as the leading mechanism was invented.  Local Differential Privacy can be achieved by adding randomized noise into  the dataset, however, too much noise could affect data quality and value of  the dataset. The thesis aims to introduce a visualization system that can  help users understand how the privacy mechanism affects data and how to  adjust noise added by those algorithms. In order to provide such a framework,  it was decided to implement Local Differential Privacy with Randomized  Response as a mechanism that would be displayed through visualization  system. Moreover, specific metrics for inspecting data privacy and utility  will be used to evaluate the mechanism's performance. By creating an interactive  visualization system that offers to adjust the epsilon parameter with  slider and instantly presenting different graphics, users will understand how  privacy affects data utility, and the opposite. In addition, including tabs in  the visualization framework that offers to view various visualization results,  users will be able to choose between insights they are interested in. The aim is to answer research questions by proposing a visualization perspective on  the Differential privacy mechanism and a specific dataset.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Partial RDF Schema Retrieval",
  "student" : "Koray Poyraz",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "There are various data structures that represent data interrelationships in the universe of information. One is a graph-based data structure, which depicts a collection of entities connected by relationships. Resource Description Framework (RDF) is a widely used data model that facilitates the storage of graph-based data. This system, unlike standardised SQL, lacks a consistent schema that evolves over time. When presenting a complete schema is crucial, the loose standards combined with timeout limits in the retrieval process pose a challenge. The objective of this master's thesis is therefore to develop a partial schema retrieval pipeline in order to solve the previously outlined problem. We evaluate the quality of our approach by measuring performance and completeness. This is conducted by running the pipeline against several SPARQL-endpoints. The pipeline lays the foundation for retrieving partial graph schemas per iteration. The result is a rendered set of visualisations of partial schemas displayed in a hierarchical aggregated view. This should provide the ability to iteratively express portion of a graph, regardless of the evolving schema.  ",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
}
,{
  "title" : "Master of Science",
  "thesis" : "A step towards Linked Open Data by incrementally visualizing an emergent RDF schema",
  "student" : "Irma Mastenbroek",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "Graphs are a popular way to store and visualize information. In the era of big data, the need for scalable and interactive visualization tools rises. In the Linked Open Data cloud, objects, events or concepts are described to have some pre-defined relationship to other entities. In a purely theoretical sense, one could create one huge knowledge graph of all interrelations of all available information known to man. However, due to historical reasons not all graph data structures are consistent and the visualization techniques for graphs do not scale up well. In this thesis, we will focus on emerging a schema of data stored in a Resource Description Framework (RDF) format. An example of data stored in RDF manner is DBpedia, a project aiming to extract all structured content created on Wikipedia. The retrieval of specific facts from an RDF dataset is often hindered by the lack of schema knowledge, further complicated by noisy data, annotation mistakes and time-outs when queries are too demanding. A schema can be seen as a clustering of the RDF-triples, downscaling the graph making interpretation and visualization possible. In this research we create an interactive node-link visualization of the global schema that enables users to discover the schema of any big RDF dataset. The tool is capable of iteratively expanding the graph as new parts of the graph arrive from the backend.  ",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
}
,{
  "title" : "Master of Science",
  "thesis" : "Generating benchmark data for Scagnostics: laying the foundation for deep learning applications",
  "student" : "Bram Dijkers",
  "start" : "2022",
  "end" : "2022",
  "abstract" : "Visual quality metrics have become essential tools for practical data exploration in high dimensional datasets. A popular visual quality metric for scatterplots is Scagnostics, as it captures the visual presence of nine different metrics. Since its publication in 2005, Scagnostics have   been applied in several other tools to detect anomalies in time series,   sort large scatterplot matrices or find specific patterns in datasets.   Researchers have used various datasets to test and validate the performance of their newly developed tools. However, it is unlikely that these datasets represent the entire pattern space of Scagnostics due to the complexity and number of possibilities found in Scagnostics. This research presents a novel method for capturing Visual Quality Metrics into a benchmark dataset. Datasets are iteratively generated through random perturbations of data points and directed towards different directions through a simulated annealing optimisation strategy. With the computational efficiency of high-performance computing, we are able to generate datasets with hundreds of thousands of diverse scatterplots representing the complete Scagnostic space. We observed the relationships between the nine different metrics and visualised how ranges of metrics exclude each other. Additionally, we aim to create datasets that could be used as training data for a deep learning model to improve the efficieny and compatibility of Visual Quality Metrics.",  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
}
,{
  "title" : "Master of Science",
  "thesis" : "Matrix reordering with GraphEmbeddings",
  "student" : "Job Heuvelmans",
  "start" : "2021",
  "end" : "2022",
  "abstract" : "Previous research in graph embedding concentrates mainly on using embeddings for downstream machine learning tasks such as node classification, edge prediction and, to a lesser extent, on visualizing these embeddings for analytical examination. This study aims to determine whether high dimensional graph embeddings can be used to uncover structures in graphs, and visualize these in two dimensional matrices. We propose a framework that embeds a graph in high dimensions; calculates the pairwise distance matrix; reorders rows and columns in this matrix; and visualizes the original graph in a new matrix exploration tool. The goal of this framework is to supply individuals with high level knowledge on relational data. We test the framework by analyzing visual quality by feeding in basic pre-generated graphs. The random walk algorithms (e.g. DeepWalk, Walkets and attentionWalk) are able to accurately visualize 4 out of 6 of the canonical data patterns for a high level understanding of the data. Nevertheless, these basic graphs do not re ect complex relational data used in many real world applications, and therefore, we introduce two novel algorithms for embedding numerical node-attributed graphs (i.e. featPMI and featWalk). These algorithms are tested on a subset of the attributed Slovakian social network Pokec, in which both the algorithms show increasing information retention over the naive embedding of DeepWalk. Furthermore, featWalk is found to be preferred over featPMI with a clearer separation of patterns, and better feature preservation. Our findings indicate the potentiality of embeddings to generate valuable high level matrix visualizations.",
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "E-sports Moneyball: Clustering the professional players of League of Legends using Node2Vec",
  "student" : "Oscar Hsieh",
  "start" : "2021",
  "end" : "2021",
  "abstract" : "Coaches, analysts and scouts are an essential part of a sports team as they bring valuable insight from the sideline. They are the key factors for player selection and strategies that impact the team. However, as statist- ics of the players do not tell the whole story, it increases the difficulty of the corresponding tasks. The recent advances in information retrieval open new opportunities by extracting information directly from videos. We demonstrate this in the field of e-sports, specifically in League of Legends. In this research, a variational autoencoder (VAE) is used to improve data analysis and decision-making with the help of spatio-temporal data and statistical data. Applying a variety of visualization methods together with the features of the VAE, we were able to provide analyses that would oth- erwise be impossible. The experiments were carried out and evaluated with technical evaluation (Model performance) and qualitative evaluation (Interviews). The results are as follows: 1. The model overfits below 100 epochs, and overfit when the epochs increase above 100 epochs 2. The user interface is clear and intuitive. The tools designed provide their own way of analysis and insight 3. Though the VAE is able to detect players that are similar to each other based on a variety of variables, the accuracy of the performance could be improved Even though the performance of the model was not as optimal as we ought to have, the techniques used were valuable and could with certainty be replicated given the right circumstances. Discarding the traditional statistical methods, this thesis shows a new approach to enhance the job of the coaches, analysts, and scouts in every type of sports and e-sports.", 
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
},{
  "title" : "Master of Science",
  "thesis" : "Interactive visual pattern search in large-scale multivariate sequential data using locality sensitive hashing algorithms",
  "student" : "Rik Koenis",
  "start" : "2021",
  "end" : "2021",
  "abstract" : "This thesis will be written during an internship at TNO on a project called Defraudify. We will be supplied with a graph-structured database that covers a significant portion of the dark web in terms of descriptive features such as user profiles, products, malware, advertisements, forum discussions and instances of fraudulent behaviour. The goal is to perform an analysis on the multivariate dataset in the context of Cyber Threat Intelligence, which aims to find actionable insights on existing and emerging threats in the information security domain. We intend to blend novel explainable artificial intelligence techniques alongside interpretable latent space representations in order to externalize the underlying decision making and behaviour of variational graph autoencoders (VGAEs). VGAEs learn interpretable latent vector representations (embeddings) from graph-structured data, and rely on Graph Convolutional Networks (GCNs) to compute the embeddings of nodes in a graph. We hypothesize that, with an interactive visual exploration tool we can externalize the behaviour and hidden representations produced by VGAEs in order to improve their explainability and interpretability. Consequently, building trust in these models. With the interactive exploration interface we intend to externalize hidden patterns discovered in the database to help TNO better understand the data and find potential instances of fraud. In addition, VGAEs can be used for link prediction, which could help complement the database.", 
  "titleshort": "M.Sc.",
  "badgeIconClass": "code"
}
]
